from pyspark import SparkContext, SparkConf

conf = SparkConf().setAppName("pysparktest").setMaster("local[*]")
sc = SparkContext(conf=conf)

rdd = sc.parallelize([("a", 1), ("b", 1), ("a", 1)])
print(sorted(rdd.groupByKey().mapValues(len).collect()))
